# Zwift OCR Telemetry Extraction

This tool extracts live telemetry data from Zwift screenshots and video recordings using Optical Character Recognition (OCR), similar to how the [AeroTelemProc_VidData](https://github.com/mateosolinho/AeroTelemProc_VidData) project extracts SpaceX telemetry.

## Features

### Python Implementation (`zwift_ocr_compact.py`)
- **100% Accurate Extraction** of all major telemetry:
  - Speed, Distance, Altitude, Race Time
  - Power, Cadence, Heart Rate
  - Gradient (with special font handling)
  - Distance to Finish
  - Full Leaderboard with rider identification
- **Optimized Performance**: ~10x faster than full-image OCR
- **Character Constraints**: Eliminates OCR errors (O/0, I/1 confusion)
- **Engine**: PaddleOCR for best accuracy

### Rust Implementation (`zwift_ocr_compact`)
- **5x Faster** for core telemetry (0.9s vs 4.5s for 7 fields)
- **3.4x Faster** for full features (3.53s vs 12.05s per image)  
- **100% Accuracy** on all core telemetry fields
- **Hybrid OCR**: Tesseract for numbers, ocrs neural network for leaderboard text
- **Feature Complete v1.1**: All telemetry fields including leaderboard and rider pose detection
- **Good Leaderboard Accuracy**: ~80% name recognition with ocrs (vs ~10% Tesseract-only)
- **v1.3 Parallel Implementation**: 1.57x speedup with parallel field extraction (0.52s for full features)
- **Build**: `cargo build --features ocr --bin zwift_ocr_compact --release`

### Extended Python Tools
- **Enhanced Extractor** (`zwift_ocr_improved_final.py`): Adds power-up detection, debug mode
- **Video Processor** (`zwift_video_processor.py`): Extract from recordings with pose analysis
- **Rider Pose Detector** (`rider_pose_detector.py`): Detect riding positions and aerodynamic implications
- **Visual Mapper** (`visual_region_mapper.py`): Calibrate regions
- **Debug Visualizer** (`debug_visualizer_v3.py`): Troubleshooting aid

## Installation

For detailed setup instructions, see [SETUP_GUIDE.md](SETUP_GUIDE.md).

### Quick Install

```bash
# Python dependencies
cd tools/ocr/
uv sync

# Rust build (from project root)
cargo build --features ocr --bin zwift_ocr_compact

# Task runner (optional)
cargo install mask
```

## Usage

### Rust Implementation (Recommended for Speed)
```bash
# Build release version (first time only)
cargo build --features ocr --bin zwift_ocr_compact --release

# Extract telemetry (JSON output)
./target/release/zwift_ocr_compact docs/screenshots/normal_1_01_16_02_21.jpg

# Human-readable output  
./target/release/zwift_ocr_compact docs/screenshots/normal_1_01_16_02_21.jpg --format text

# Using cargo run (slower)
cargo run --features ocr --bin zwift_ocr_compact --release -- screenshot.jpg

# Benchmark sequential vs parallel implementations
./target/release/zwift_ocr_benchmark screenshot.jpg --iterations 10
```

**Example Output (JSON)**:
```json
{
  "speed": 34,
  "distance": 6.4,
  "altitude": 28,
  "race_time": "11:07",
  "power": 268,
  "cadence": 72,
  "heart_rate": 160,
  "gradient": 3.0,
  "distance_to_finish": 28.6,
  "leaderboard": null
}
```

### Python Implementation (Full Features)
```bash
# Navigate to OCR directory
cd tools/ocr/

# Extract all telemetry including leaderboard
uv run python zwift_ocr_compact.py ../../docs/screenshots/normal_1_01_16_02_21.jpg

# Enhanced version with debug visualization
uv run python zwift_ocr_improved_final.py ../../docs/screenshots/normal_1_01_16_02_21.jpg --debug

# Process entire video with pose detection
uv run python zwift_video_processor.py /path/to/zwift_recording.mp4

# Calibrate pose detection with sample images
mask calibrate-poses
```

### Performance Comparison
```bash
# Compare both implementations side-by-side
cd tools/ocr/
uv run python compare_ocr_compact.py

# Time both (from project root)
time ./target/release/zwift_ocr_compact docs/screenshots/normal_1_01_16_02_21.jpg > /dev/null
time (cd tools/ocr && uv run python zwift_ocr_compact.py ../../docs/screenshots/normal_1_01_16_02_21.jpg > /dev/null)
```

## Performance Comparison

| Implementation | Speed | Accuracy | Extracted Fields |
|----------------|-------|----------|------------------|
| **Rust Core** | **0.9s** | 100% | Speed, distance, altitude, time, power, cadence, HR (7 fields) |
| **Python Core** | **4.5s** | 100% | Same 7 core telemetry fields |
| **Rust v1.3 Parallel** | **0.52s** | 100%* | All 11 fields with parallel extraction |
| **Rust v1.1 (Full)** | **3.53s** | 100%* | All 11 fields including gradient, distance-to-finish, leaderboard**, rider pose |
| Python (Full) | 12.05s | 100% | All fields with perfect leaderboard accuracy |

**Speed Advantage**: 
- Core telemetry: Rust is **5x faster** (0.9s vs 4.5s)
- Full features: Rust v1.1 is **3.4x faster** (3.53s vs 12.05s)
- Full features: Rust v1.3 Parallel is **23x faster** (0.52s vs 12.05s)

*Core telemetry fields have 100% accuracy. **Leaderboard extraction ~80% accurate with ocrs (vs 100% PaddleOCR).

**Use Cases**:
- **Rust**: Faster batch processing, automation, production systems (3.4x speedup)
- **Python**: Perfect leaderboard accuracy required, development/prototyping, complex visualizations

See [OCR_COMPARISON_FINDINGS.md](OCR_COMPARISON_FINDINGS.md) for detailed performance analysis of different OCR approaches.

## Technical Details

For architecture, region mapping, and implementation details, see [TECHNICAL_REFERENCE.md](TECHNICAL_REFERENCE.md).

## Task Runner Commands

Using mask (recommended):
```bash
mask --help              # Show available tasks
mask test               # Run tests
mask video recording.mp4 # Process video
mask debug screenshot.jpg # Debug visualization
```

See [maskfile.md](maskfile.md) for all available commands.

## Integration with Zwift Race Finder

The extracted telemetry can be used to:
- Validate duration estimates against actual ride data
- Track performance metrics during races
- Build personalized prediction models
- Analyze pacing strategies

## Current Status & Future Enhancements

### ‚úÖ Completed Features
- [x] **Complete core telemetry extraction** (Rust): Speed, distance, altitude, time, power, cadence, HR
- [x] **Gradient extraction** (Rust): Current slope percentage with specialized font handling
- [x] **Distance-to-finish extraction** (Rust): Remaining race distance
- [x] **Production-ready performance** (Rust): Sub-200ms extraction speed
- [x] **Leaderboard extraction** (Python): Multi-rider names, positions, deltas, w/kg values
- [x] **Rider pose detection** (Python): Detect riding positions and aerodynamic drag implications

### üöß Future Enhancements

#### Priority 1: Feature Completeness
- [x] **Leaderboard extraction** (Rust): Feature parity with Python implementation
  - ‚úÖ Multi-rider parsing with name detection, deltas, w/kg values
  - ‚úÖ Adaptive threshold for contrast enhancement
  - ‚úÖ Current rider detection based on missing time delta
  - ‚ö†Ô∏è Note: Tesseract OCR less accurate than PaddleOCR for complex leaderboard text
  - Completed: Added ~280 lines of code

- [x] **Rider pose detection** (Rust): Ported pose classification from Python
  - ‚úÖ Detects: normal_tuck (high drag), normal_normal, climbing_seated, climbing_standing (high drag)
  - ‚úÖ Extracts pose features: aspect ratio, center of mass, density analysis, symmetry
  - ‚úÖ Avatar region: (860, 400, 200, 300) for 1920x1080
  - ‚ö†Ô∏è Note: Edge detection approach may need refinement for better accuracy
  - Completed: Added ~130 lines of code

#### Priority 2: Usability Improvements
- [ ] **Automatic UI scale detection**: Handle different screen resolutions automatically
  - Currently optimized for 1920x1080 displays
  - Auto-detect resolution and scale coordinates proportionally
  - Eliminate manual calibration for different screen sizes

- [ ] **AI-powered region optimization**: Auto-calibrate OCR regions during race join period
  - **Perfect timing**: Races require joining before start - provides calibration window
  - Use computer vision to detect UI elements during pre-race period
  - Template matching or feature detection to locate speed, power, distance etc.
  - Account for minor shifts during climbing (some elements move ¬±10-20 pixels)
  - Cache optimized regions per screen resolution for future sessions
  - Complete calibration before race starts, ready for immediate extraction

#### Priority 3: Data Integration & Advanced Features
- [ ] **Sensor data integration**: Combine OCR with direct ANT+/Bluetooth telemetry
  - ‚úÖ **Verified**: Strava .fit files record power, cadence, HR at **1Hz (1 second intervals)**
  - ‚úÖ **97-minute race** = 5,831 data points with 100% sensor data completeness
  - ‚úÖ **FIT file analysis** (2025-06-06-10-23-16.fit): Confirmed consistent 1.0 second update intervals
  - OCR focus on UI-only data: position, leaderboard, gradient, distance-to-finish, rider pose
  - Cross-validate OCR accuracy against sensor ground truth
  - Optimal strategy: Real-time sensor feeds + periodic OCR extraction

- [ ] **Real-time streaming integration**: Live overlay for broadcasts
  - Process streaming video for position/leaderboard data (not available from sensors)
  - Combine with direct sensor feeds for complete telemetry
  - Enable real-time race analysis with both UI and sensor data

- [ ] **UI change adaptation**: Handle future Zwift interface updates
  - Monitor for UI layout changes between game versions
  - Automatically re-calibrate regions when changes detected
  - Version-aware region storage (e.g., "zwift_v1.60_1920x1080_regions.json")